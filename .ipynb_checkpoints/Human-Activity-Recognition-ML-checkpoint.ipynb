{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb9c8808",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install git+https://github.com/tensorflow/docs\n",
    "#!pip install imutils\n",
    "#!pip install imagio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c74cda49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_docs.vis import embed\n",
    "from tensorflow import keras\n",
    "from imutils import paths\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imageio\n",
    "import cv2 \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bb20969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>video_name</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>dataset/test/dancing/dancing (21).mp4</td>\n",
       "      <td>dancing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>dataset/test/dancing/dancing (22).mp4</td>\n",
       "      <td>dancing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>dataset/test/dancing/dancing (23.mp4</td>\n",
       "      <td>dancing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>dataset/test/dancing/dancing (24).mp4</td>\n",
       "      <td>dancing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>dataset/test/dancing/dancing (25).mp4</td>\n",
       "      <td>dancing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>dataset/test/exercise/exercis (1).mp4</td>\n",
       "      <td>exercise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>dataset/test/exercise/exercis (2).mp4</td>\n",
       "      <td>exercise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>dataset/test/exercise/exercis (3).mp4</td>\n",
       "      <td>exercise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>dataset/test/exercise/exercise (25).mp4</td>\n",
       "      <td>exercise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>dataset/test/exercise/exercise (26).mp4</td>\n",
       "      <td>exercise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>dataset/test/exercise/exercise (27).mp4</td>\n",
       "      <td>exercise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>dataset/test/exercise/exercise (28).mp4</td>\n",
       "      <td>exercise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>dataset/test/exercise/exercise.mp4</td>\n",
       "      <td>exercise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>dataset/test/yoga/yog (1).mp4</td>\n",
       "      <td>yoga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>dataset/test/yoga/yog (2).mp4</td>\n",
       "      <td>yoga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>dataset/test/yoga/yog (3).mp4</td>\n",
       "      <td>yoga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>dataset/test/yoga/yog (4).mp4</td>\n",
       "      <td>yoga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>dataset/test/yoga/yoga (24).mp4</td>\n",
       "      <td>yoga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>dataset/test/yoga/yoga (25).mp4</td>\n",
       "      <td>yoga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>dataset/test/yoga/yoga (26).mp4</td>\n",
       "      <td>yoga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>dataset/test/yoga/yoga (27).mp4</td>\n",
       "      <td>yoga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>dataset/test/yoga/yoga (28).mp4</td>\n",
       "      <td>yoga</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                               video_name       tag\n",
       "0            0    dataset/test/dancing/dancing (21).mp4   dancing\n",
       "1            1    dataset/test/dancing/dancing (22).mp4   dancing\n",
       "2            2     dataset/test/dancing/dancing (23.mp4   dancing\n",
       "3            3    dataset/test/dancing/dancing (24).mp4   dancing\n",
       "4            4    dataset/test/dancing/dancing (25).mp4   dancing\n",
       "5            5    dataset/test/exercise/exercis (1).mp4  exercise\n",
       "6            6    dataset/test/exercise/exercis (2).mp4  exercise\n",
       "7            7    dataset/test/exercise/exercis (3).mp4  exercise\n",
       "8            8  dataset/test/exercise/exercise (25).mp4  exercise\n",
       "9            9  dataset/test/exercise/exercise (26).mp4  exercise\n",
       "10          10  dataset/test/exercise/exercise (27).mp4  exercise\n",
       "11          11  dataset/test/exercise/exercise (28).mp4  exercise\n",
       "12          12       dataset/test/exercise/exercise.mp4  exercise\n",
       "13          13            dataset/test/yoga/yog (1).mp4      yoga\n",
       "14          14            dataset/test/yoga/yog (2).mp4      yoga\n",
       "15          15            dataset/test/yoga/yog (3).mp4      yoga\n",
       "16          16            dataset/test/yoga/yog (4).mp4      yoga\n",
       "17          17          dataset/test/yoga/yoga (24).mp4      yoga\n",
       "18          18          dataset/test/yoga/yoga (25).mp4      yoga\n",
       "19          19          dataset/test/yoga/yoga (26).mp4      yoga\n",
       "20          20          dataset/test/yoga/yoga (27).mp4      yoga\n",
       "21          21          dataset/test/yoga/yoga (28).mp4      yoga"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df=pd.read_csv('train.csv')\n",
    "test_df=pd.read_csv('test.csv')\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dcbf647",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE=224\n",
    "\n",
    "def crop_image_square(frame):\n",
    "    x,y=frame.shape[0:2]\n",
    "    min_dim=min(x,y)\n",
    "    start_x=(x//2)-(min_dim//2)\n",
    "    start_y=(y//2)-(min_dim//2)\n",
    "    return frame[start_y:star_y+min_dim,start_x:start_x+min_dim]\n",
    "\n",
    "def load_video(path, max_frames=0,resize=(IMG_SIZE,IMG_SIZE)):\n",
    "    cap=cv2.VideoCapture(path)\n",
    "    frames=[]\n",
    "    try:\n",
    "        while True:\n",
    "            ret,frame=cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame=crop_image_square(frame)\n",
    "            frame=cv2.resize(frame, resize)\n",
    "            frame=frame[:,:,[2,1,0]]\n",
    "            frames.append(frame)\n",
    "            if len(frames)==max_frames:\n",
    "                break\n",
    "    finally:\n",
    "        cap.release()\n",
    "    return np.array(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b4ba126",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_features_extractor():\n",
    "    features_extractor=keras.applications.InceptionV3(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        pooling='avg',\n",
    "        input_shape=(IMG_SIZE,IMG_SIZE,3),\n",
    "    )\n",
    "    preprocess_input=keras.applications.inception_v3.preprocess_input\n",
    "    inputs=kreas.Input((IMG_SIZE,IMG_SIZE,3))\n",
    "    preprocessed=preprocess_input(inputs)\n",
    "    \n",
    "    outputs=feature_extractor(preprocessed)\n",
    "    return keras.Model(inputs,outputs,name=\"feature_extractor\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "865b3c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dancing', 'exercise', 'yoga']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2]], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_processor=keras.layers.StringLookup(num_oov_indices=0,vocabulary=pd.unique(train_df[\"tag\"]))\n",
    "print(label_processor.get_vocabulary())\n",
    "\n",
    "labels=train_df['tag'].values\n",
    "labels=label_processor(labels[...,None]).numpy()\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d14782a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=64\n",
    "EPOCHS=100\n",
    "MAX_SEQ_LENGTH=20\n",
    "NUM_FEATURES=2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d6ac2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame features in data set: (145, 20, 2048)\n",
      "Frame masks in data set: (145, 20)\n",
      "train_labels in train set: (145, 1)\n",
      "test_labels in train set: (22, 1)\n"
     ]
    }
   ],
   "source": [
    "def prepare_all_videos(df, root_dir):\n",
    "    num_samples=len(df)\n",
    "    video_paths=df['video_name'].values.tolist()\n",
    "    labels=df['tag'].values\n",
    "    labels=label_processor(labels[...,None]).numpy()\n",
    "    \n",
    "    frame_masks=np.zeros(shape=(num_samples,MAX_SEQ_LENGTH),dtype=\"bool\")\n",
    "    frame_features=np.zeros(shape=(num_samples,MAX_SEQ_LENGTH,NUM_FEATURES),dtype=\"float32\")\n",
    "    \n",
    "    for idx,path in enumerate(video_paths):\n",
    "        frames=load_video(os.path.join(root_dir,path))\n",
    "        frames=frames[None,...]\n",
    "        temp_frame_mask=np.zeros(shape=(1,MAX_SEQ_LENGTH),dtype='bool')\n",
    "        temp_frame_features=np.zeros(shape=(1,MAX_SEQ_LENGTH,NUM_FEATURES),dtype=\"float32\")\n",
    "        \n",
    "        for i,batch in enumerate(frames):\n",
    "            video_length=batch.shape[0]\n",
    "            length=min(MAX_SEQ_LENGTH,video_length)\n",
    "            for j in range(length):\n",
    "                temp_frame_feature[i,j,:]=feature_extractor.predict(\n",
    "                batch[None,j,:])\n",
    "                temp_frame_mask[i,:length]=1\n",
    "            frame_masks[idx,]=temp_frame_mask.squeeze()\n",
    "            frame_features[idx,]=temp_frame_features.squeeze()\n",
    "            \n",
    "    return (frame_features,frame_masks),labels\n",
    "\n",
    "train_data,train_labels=prepare_all_videos(train_df,\"train\")\n",
    "test_data,test_labels=prepare_all_videos(test_df,\"test\")\n",
    "\n",
    "train_data\n",
    "print(f'Frame features in data set: {train_data[0].shape}')\n",
    "print(f'Frame masks in data set: {train_data[1].shape}')\n",
    "\n",
    "print(f'train_labels in train set: {train_labels.shape}')\n",
    "print(f'test_labels in train set: {test_labels.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d865532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0980 - accuracy: 0.4257\n",
      "Epoch 1: val_loss improved from inf to 1.10351, saving model to ./tmp\\video_classifier\n",
      "4/4 [==============================] - 18s 2s/step - loss: 1.0980 - accuracy: 0.4257 - val_loss: 1.1035 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0959 - accuracy: 0.4950\n",
      "Epoch 2: val_loss did not improve from 1.10351\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 1.0959 - accuracy: 0.4950 - val_loss: 1.1084 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0938 - accuracy: 0.5000\n",
      "Epoch 3: val_loss did not improve from 1.10351\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 1.0937 - accuracy: 0.4950 - val_loss: 1.1134 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0917 - accuracy: 0.4792\n",
      "Epoch 4: val_loss did not improve from 1.10351\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 1.0916 - accuracy: 0.4950 - val_loss: 1.1183 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0896 - accuracy: 0.5000\n",
      "Epoch 5: val_loss did not improve from 1.10351\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 1.0895 - accuracy: 0.4950 - val_loss: 1.1232 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0875 - accuracy: 0.5000\n",
      "Epoch 6: val_loss did not improve from 1.10351\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 1.0874 - accuracy: 0.4950 - val_loss: 1.1281 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0855 - accuracy: 0.5000\n",
      "Epoch 7: val_loss did not improve from 1.10351\n",
      "4/4 [==============================] - 0s 90ms/step - loss: 1.0854 - accuracy: 0.4950 - val_loss: 1.1330 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0829 - accuracy: 0.5000\n",
      "Epoch 8: val_loss did not improve from 1.10351\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 1.0833 - accuracy: 0.4950 - val_loss: 1.1378 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0815 - accuracy: 0.5000\n",
      "Epoch 9: val_loss did not improve from 1.10351\n",
      "4/4 [==============================] - 0s 93ms/step - loss: 1.0813 - accuracy: 0.4950 - val_loss: 1.1426 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0795 - accuracy: 0.4792\n",
      "Epoch 10: val_loss did not improve from 1.10351\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 1.0793 - accuracy: 0.4950 - val_loss: 1.1474 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0774 - accuracy: 0.4950\n",
      "Epoch 11: val_loss did not improve from 1.10351\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 1.0774 - accuracy: 0.4950 - val_loss: 1.1522 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0755 - accuracy: 0.4950\n",
      "Epoch 12: val_loss did not improve from 1.10351\n",
      "4/4 [==============================] - 0s 91ms/step - loss: 1.0755 - accuracy: 0.4950 - val_loss: 1.1569 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0738 - accuracy: 0.4896\n",
      "Epoch 13: val_loss did not improve from 1.10351\n",
      "4/4 [==============================] - 0s 100ms/step - loss: 1.0735 - accuracy: 0.4950 - val_loss: 1.1616 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0720 - accuracy: 0.4688\n",
      "Epoch 14: val_loss did not improve from 1.10351\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 1.0717 - accuracy: 0.4950 - val_loss: 1.1664 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0689 - accuracy: 0.5104\n",
      "Epoch 15: val_loss did not improve from 1.10351\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 1.0698 - accuracy: 0.4950 - val_loss: 1.1710 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0682 - accuracy: 0.5104\n",
      "Epoch 16: val_loss did not improve from 1.10351\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 1.0680 - accuracy: 0.4950 - val_loss: 1.1756 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0665 - accuracy: 0.5000\n",
      "Epoch 17: val_loss did not improve from 1.10351\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 1.0662 - accuracy: 0.4950 - val_loss: 1.1802 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0634 - accuracy: 0.5104\n",
      "Epoch 18: val_loss did not improve from 1.10351\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 1.0645 - accuracy: 0.4950 - val_loss: 1.1848 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0617 - accuracy: 0.4896\n",
      "Epoch 19: val_loss did not improve from 1.10351\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 1.0627 - accuracy: 0.4950 - val_loss: 1.1892 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0613 - accuracy: 0.4896\n",
      "Epoch 20: val_loss did not improve from 1.10351\n",
      "4/4 [==============================] - 0s 92ms/step - loss: 1.0610 - accuracy: 0.4950 - val_loss: 1.1936 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0593 - accuracy: 0.4950\n",
      "Epoch 21: val_loss did not improve from 1.10351\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 1.0593 - accuracy: 0.4950 - val_loss: 1.1981 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0576 - accuracy: 0.4950\n",
      "Epoch 22: val_loss did not improve from 1.10351\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 1.0576 - accuracy: 0.4950 - val_loss: 1.2028 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0558 - accuracy: 0.4950\n",
      "Epoch 23: val_loss did not improve from 1.10351\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 1.0558 - accuracy: 0.4950 - val_loss: 1.2075 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0545 - accuracy: 0.4896\n",
      "Epoch 24: val_loss did not improve from 1.10351\n",
      "4/4 [==============================] - 0s 94ms/step - loss: 1.0541 - accuracy: 0.4950 - val_loss: 1.2122 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0528 - accuracy: 0.4792\n",
      "Epoch 25: val_loss did not improve from 1.10351\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 1.0524 - accuracy: 0.4950 - val_loss: 1.2170 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0510 - accuracy: 0.4896\n",
      "Epoch 26: val_loss did not improve from 1.10351\n",
      "4/4 [==============================] - 0s 90ms/step - loss: 1.0506 - accuracy: 0.4950 - val_loss: 1.2217 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0488 - accuracy: 0.4950\n",
      "Epoch 27: val_loss did not improve from 1.10351\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 1.0488 - accuracy: 0.4950 - val_loss: 1.2265 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0457 - accuracy: 0.4896\n",
      "Epoch 28: val_loss did not improve from 1.10351\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 1.0472 - accuracy: 0.4950 - val_loss: 1.2312 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0460 - accuracy: 0.4896\n",
      "Epoch 29: val_loss did not improve from 1.10351\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 1.0455 - accuracy: 0.4950 - val_loss: 1.2357 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0443 - accuracy: 0.5000\n",
      "Epoch 30: val_loss did not improve from 1.10351\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 1.0439 - accuracy: 0.4950 - val_loss: 1.2403 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 70ms/step - loss: 1.0992 - accuracy: 0.2273\n",
      "Test accuracy: 22.73%\n"
     ]
    }
   ],
   "source": [
    "def get_sequence_model():\n",
    "    class_vocab=label_processor.get_vocabulary()\n",
    "    frame_features_input=keras.Input((MAX_SEQ_LENGTH,NUM_FEATURES))\n",
    "    mask_input=keras.Input((MAX_SEQ_LENGTH),dtype='bool')\n",
    "    \n",
    "    x=keras.layers.GRU(16,return_sequences=True)(frame_features_input,mask=mask_input)\n",
    "    x=keras.layers.GRU(8)(x)\n",
    "    x=keras.layers.Dropout(0.4)(x)\n",
    "    x=keras.layers.Dense(8,activation='relu')(x)\n",
    "    output=keras.layers.Dense(len(class_vocab),activation='softmax')(x)\n",
    "    \n",
    "    rnn_model=keras.Model([frame_features_input,mask_input],output)\n",
    "    rnn_model.compile(\n",
    "        loss=\"sparse_categorical_crossentropy\",optimizer=\"adam\",metrics=['accuracy']\n",
    "    )\n",
    "    return rnn_model\n",
    "EPOCHS=30\n",
    "def run_experiment():\n",
    "    file_path='./tmp/video_classifier'\n",
    "    checkpoint=keras.callbacks.ModelCheckpoint(\n",
    "        file_path,save_weights_only=True, save_best_only=True, verbose=1\n",
    "    )\n",
    "    seq_model=get_sequence_model()\n",
    "    history=seq_model.fit(\n",
    "        [train_data[0],train_data[1]],\n",
    "        train_labels,\n",
    "        validation_split=0.3,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=[checkpoint]\n",
    "    )\n",
    "    seq_model.load_weights(file_path)\n",
    "    _,accuracy=seq_model.evaluate([test_data[0],test_data[1]],test_labels)\n",
    "    print(f'Test accuracy: {round(accuracy*100,2)}%')\n",
    "    return history, seq_model\n",
    "\n",
    "_,sequence_model=run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20959b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test video path: dataset/test/exercise/exercise (27).mp4\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "dancing:33.42%\n",
      "exercise:33.41%\n",
      "yoga:33.17%\n"
     ]
    }
   ],
   "source": [
    "def prepare_single_video(frames):\n",
    "    frames=frames[None,...]\n",
    "    frame_mask=np.zeros(shape=(1,MAX_SEQ_LENGTH,),dtype='bool')\n",
    "    frame_features=np.zeros(shape=(1,MAX_SEQ_LENGTH,NUM_FEATURES),dtype='float32')\n",
    "    \n",
    "    for i,batch in enumerate(frames):\n",
    "        video_length=batch.shape[0]\n",
    "        length=min(MAX_SEQ_LENGTH,video_length)\n",
    "        for j in range(length):\n",
    "            frame_features[i,j,:]=feature_extractor.predict(batch[None,j,:])\n",
    "        frame_mask[i,:length]=1\n",
    "    return frame_features,frame_mask\n",
    "\n",
    "def sequence_prediction(path):\n",
    "    class_vocab=label_processor.get_vocabulary()\n",
    "    frames=load_video(os.path.join('test',path))\n",
    "    frame_features,frame_mask=prepare_single_video(frames)\n",
    "    probabilities=sequence_model.predict([frame_features,frame_mask])[0]\n",
    "    \n",
    "    for i in np.argsort(probabilities)[::-1]:\n",
    "        print(f\"{class_vocab[i]}:{probabilities[i]*100:5.2f}%\")\n",
    "    return frames\n",
    "test_video=np.random.choice(test_df[\"video_name\"].values.tolist())\n",
    "print(f\"Test video path: {test_video}\")\n",
    "test_frames=sequence_prediction(test_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9293ff1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
